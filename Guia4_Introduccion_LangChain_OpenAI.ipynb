{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83152e03",
   "metadata": {},
   "source": [
    "# Guía 4 — Introducción a LangChain con OpenAI API\n",
    "Curso: **IA en el Aula — Nivel Avanzado**  \n",
    "Profesor: **Luis Daniel Benavides Navarro**  \n",
    "Fecha: **Octubre 2025**\n",
    "\n",
    "En esta guía aprenderás los conceptos básicos de **LangChain**, una librería diseñada para construir aplicaciones impulsadas por modelos de lenguaje, integrando la API de OpenAI con flujos más complejos. Exploraremos cómo crear un primer **prompt chain**, administrar memoria y usar herramientas para componer respuestas inteligentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4929bd",
   "metadata": {},
   "source": [
    "## 1️⃣ Instalación y configuración inicial\n",
    "LangChain se instala como cualquier otra librería de Python. También usaremos `python-dotenv` para gestionar la clave de OpenAI. Ejecute la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca0e6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (2.6.1)\n",
      "Collecting langchain\n",
      "  Downloading langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (1.2.1)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain)\n",
      "  Downloading langchain_core-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.0 (from langchain)\n",
      "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading langsmith-0.4.38-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading ormsgpack-1.11.0-cp311-cp311-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading orjson-3.11.4-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai)\n",
      "  Downloading regex-2025.10.23-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\diego.macia-d\\documents\\hello_ai_vs\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading langchain-1.0.2-py3-none-any.whl (107 kB)\n",
      "Downloading langchain_core-1.0.1-py3-none-any.whl (467 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
      "Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading langsmith-0.4.38-py3-none-any.whl (397 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_openai-1.0.1-py3-none-any.whl (81 kB)\n",
      "Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
      "   ----------------------- --------------- 524.3/879.4 kB 17.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 786.4/879.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 879.4/879.4 kB 1.2 MB/s  0:00:00\n",
      "Downloading orjson-3.11.4-cp311-cp311-win_amd64.whl (131 kB)\n",
      "Downloading ormsgpack-1.11.0-cp311-cp311-win_amd64.whl (112 kB)\n",
      "Downloading regex-2025.10.23-cp311-cp311-win_amd64.whl (277 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl (506 kB)\n",
      "Installing collected packages: zstandard, xxhash, tenacity, regex, ormsgpack, orjson, jsonpatch, tiktoken, requests-toolbelt, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph, langchain\n",
      "\n",
      "   ---- -----------------------------------  2/17 [tenacity]\n",
      "   ------- --------------------------------  3/17 [regex]\n",
      "   -------------- -------------------------  6/17 [jsonpatch]\n",
      "   ------------------ ---------------------  8/17 [requests-toolbelt]\n",
      "   ------------------ ---------------------  8/17 [requests-toolbelt]\n",
      "   ------------------ ---------------------  8/17 [requests-toolbelt]\n",
      "   --------------------- ------------------  9/17 [langsmith]\n",
      "   --------------------- ------------------  9/17 [langsmith]\n",
      "   --------------------- ------------------  9/17 [langsmith]\n",
      "   --------------------- ------------------  9/17 [langsmith]\n",
      "   --------------------- ------------------  9/17 [langsmith]\n",
      "   ----------------------- ---------------- 10/17 [langgraph-sdk]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ------------------------- -------------- 11/17 [langchain-core]\n",
      "   ---------------------------- ----------- 12/17 [langgraph-checkpoint]\n",
      "   ------------------------------ --------- 13/17 [langchain-openai]\n",
      "   -------------------------------- ------- 14/17 [langgraph-prebuilt]\n",
      "   ----------------------------------- ---- 15/17 [langgraph]\n",
      "   ----------------------------------- ---- 15/17 [langgraph]\n",
      "   ----------------------------------- ---- 15/17 [langgraph]\n",
      "   ----------------------------------- ---- 15/17 [langgraph]\n",
      "   ----------------------------------- ---- 15/17 [langgraph]\n",
      "   ------------------------------------- -- 16/17 [langchain]\n",
      "   ------------------------------------- -- 16/17 [langchain]\n",
      "   ---------------------------------------- 17/17 [langchain]\n",
      "\n",
      "Successfully installed jsonpatch-1.33 langchain-1.0.2 langchain-core-1.0.1 langchain-openai-1.0.1 langgraph-1.0.1 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 langsmith-0.4.38 orjson-3.11.4 ormsgpack-1.11.0 regex-2025.10.23 requests-toolbelt-1.0.0 tenacity-9.1.2 tiktoken-0.12.0 xxhash-3.6.0 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai langchain python-dotenv langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aee39b5",
   "metadata": {},
   "source": [
    "## 2️⃣ Cargar variables de entorno y cliente OpenAI\n",
    "Crea un archivo `.env` con tu clave de API y cárgala para poder usarla dentro de LangChain. Esto evita exponer tu clave en el código fuente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b3fcb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente LangChain con OpenAI inicializado correctamente.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()  # Cargar archivo .env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"No se encontró la clave OPENAI_API_KEY en el archivo .env\")\n",
    "\n",
    "# Crear cliente LangChain con OpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "print(\"Cliente LangChain con OpenAI inicializado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2926d",
   "metadata": {},
   "source": [
    "## 3️⃣ Primer ejemplo: Prompt simple con LangChain\n",
    "LangChain utiliza **chains** (cadenas de pasos) para procesar información. Comencemos con una cadena simple que envía un mensaje al modelo y obtiene la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0769dbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El aprendizaje automático es una rama de la inteligencia artificial que permite a las computadoras aprender de datos y mejorar su rendimiento en tareas específicas sin ser programadas explícitamente para cada una. Utiliza algoritmos para identificar patrones y hacer predicciones basadas en la información proporcionada, adaptándose con el tiempo a medida que se reciben más datos.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Initialize the LLM (uses your OpenAI API key from environment)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "# Create a simple prompt\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explica en dos frases el concepto de {tema}.\"\n",
    ")\n",
    "\n",
    "# Combine the components using LCEL (LangChain Expression Language)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run it\n",
    "result = chain.invoke({\"tema\": \"aprendizaje automático\"})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5349f8b",
   "metadata": {},
   "source": [
    "### Explicación\n",
    "- **ChatPromptTemplate:** define la estructura del mensaje que se envía al modelo.\n",
    "- **ChatOpenAI:** la conexión real al modelo.\n",
    "- **chain** crea la cadena de componentes usando LCEL (LangChain Expression Language).\n",
    "- **StrOutputParser** convierte la salida estructurada del modelo en texto plano.\n",
    "- **chain.invoke:** ejecuta la cadena pasando los valores del prompt.\n",
    "\n",
    "Este patrón permite reutilizar prompts para distintos temas o contextos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939352f",
   "metadata": {},
   "source": [
    "## 4️⃣ Ejemplo 2: Encadenar múltiples pasos\n",
    "LangChain permite combinar varios pasos en una misma ejecución. En este ejemplo, crearemos dos prompts: uno para definir un tema y otro para generar una aplicación educativa basada en el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6cd03c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Aplicación Educativa: \"ExplorAR\" - Plataforma de Aprendizaje Interactivo con Realidad Aumentada**\n",
      "\n",
      "**Descripción de la Aplicación:**\n",
      "\"ExplorAR\" es una aplicación educativa diseñada para enriquecer el aprendizaje en diversas materias a través de la realidad aumentada. La plataforma permite a los estudiantes interactuar con contenido educativo de manera dinámica y visual, superponiendo información digital sobre su entorno físico.\n",
      "\n",
      "**Características Principales:**\n",
      "\n",
      "1. **Exploraciones de Campo:**\n",
      "   - Los estudiantes pueden realizar excursiones virtuales a lugares históricos, museos, o sitios naturales. A través de la cámara de su dispositivo, pueden ver información adicional sobre los objetos o lugares en su entorno real, como datos históricos, descripciones de especies, o artefactos relevantes.\n",
      "\n",
      "2. **Modelos 3D Interactivos:**\n",
      "   - La aplicación incluye modelos 3D de estructuras, organismos, o conceptos científicos que los estudiantes pueden manipular. Por ejemplo, en una clase de biología, los alumnos pueden ver un modelo 3D de una célula y explorar sus partes, interactuando con cada componente para obtener información detallada.\n",
      "\n",
      "3. **Ejercicios de Aprendizaje Contextual:**\n",
      "   - Los docentes pueden crear ejercicios que utilicen la RA para reforzar conceptos. Por ejemplo, en matemáticas, los estudiantes pueden resolver problemas superponiendo figuras geométricas en su entorno, lo que les permite visualizar y manipular conceptos abstractos.\n",
      "\n",
      "4. **Gamificación del Aprendizaje:**\n",
      "   - \"ExplorAR\" incorpora elementos de juego, donde los estudiantes pueden completar misiones o desafíos relacionados con el contenido del curso. Al completar tareas, pueden ganar puntos o insignias, fomentando la motivación y el compromiso.\n",
      "\n",
      "5. **Colaboración y Proyectos en Grupo:**\n",
      "   - La aplicación permite que los estudiantes trabajen en proyectos colaborativos, donde pueden compartir su visión aumentada del entorno y crear presentaciones utilizando elementos de RA. Esto fomenta el trabajo en equipo y la comunicación.\n",
      "\n",
      "6. **Integración de Contenido Curricular:**\n",
      "   - Los docentes pueden integrar fácilmente contenido curricular en la aplicación, creando lecciones personalizadas que se alineen con los estándares educativos. Esto permite una adaptación a diferentes niveles de aprendizaje y estilos educativos.\n",
      "\n",
      "**Beneficios:**\n",
      "- **Aprendizaje Activo:** Los estudiantes se involucran de manera activa con el material, lo que mejora la retención de información.\n",
      "- **Desarrollo de Habilidades Técnicas:** Al utilizar tecnología de RA, los estudiantes desarrollan habilidades digitales que son valiosas en el mundo actual.\n",
      "- **Estimulación del Pensamiento Crítico:** La interacción con elementos virtuales en un contexto real fomenta el análisis y la resolución de problemas.\n",
      "\n",
      "**Conclusión:**\n",
      "\"ExplorAR\" representa una innovadora forma de aprendizaje que combina la educación con la tecnología de realidad aumentada, ofreciendo a los estudiantes experiencias enriquecedoras que van más allá de la enseñanza tradicional. Esta aplicación no solo hace que el aprendizaje sea más atractivo, sino que también prepara a los estudiantes para un futuro donde la tecnología y la educación están cada vez más interconectadas.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "# 1) LLM (usa tu OPENAI_API_KEY en el entorno)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "to_str = StrOutputParser()\n",
    "\n",
    "# 2) Paso 1: explicar brevemente el concepto de {tema}\n",
    "primer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explica brevemente el concepto de {tema}.\"\n",
    ")\n",
    "primer_paso = primer_prompt | llm | to_str\n",
    "# `primer_paso` produce un string, por ejemplo: \"La realidad aumentada es ...\"\n",
    "\n",
    "# 3) Paso 2: proponer una aplicación educativa usando la salida del paso 1 como {concepto}\n",
    "segundo_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Propón una aplicación educativa del siguiente concepto: {concepto}.\"\n",
    ")\n",
    "segundo_paso = segundo_prompt | llm | to_str\n",
    "\n",
    "# 4) Encadenar: mapear la entrada {tema} al primer paso, y su salida a {concepto} del segundo\n",
    "cadena_secuencial = {\"concepto\": primer_paso} | segundo_paso\n",
    "\n",
    "# 5) Ejecutar la cadena completa\n",
    "resultado = cadena_secuencial.invoke({\"tema\": \"realidad aumentada\"})\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf949db6",
   "metadata": {},
   "source": [
    "### Explicación\n",
    "- **cadena_secuencial:** permite conectar varias cadenas; la salida de una se convierte en la entrada de la siguiente.\n",
    "- En este caso, el modelo primero explica el tema y luego sugiere una aplicación educativa.\n",
    "\n",
    "Este tipo de flujo es ideal para generar contenido didáctico o ideas para proyectos en clase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0483d0",
   "metadata": {},
   "source": [
    "## 5️⃣ Ejemplo 3: Añadir memoria a la conversación\n",
    "LangChain incluye módulos de **memoria** para mantener contexto entre múltiples interacciones. Esto permite simular conversaciones educativas más naturales, donde el modelo recuerda temas previos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d363f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instalar si hace falta:\n",
    "# %pip install -U langchain langchain-openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM (requiere OPENAI_API_KEY en el entorno)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "to_str = StrOutputParser()\n",
    "\n",
    "# Prompt con hueco para el historial\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Eres un asistente educativo claro y conciso.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),      # ← aquí va la memoria\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Cadena base\n",
    "chain = prompt | llm | to_str\n",
    "\n",
    "# Memoria simple como lista de mensajes\n",
    "history: list = []\n",
    "\n",
    "def chat(user_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Envía un turno del usuario, usa el historial y actualiza la memoria\n",
    "    con el par (usuario, asistente).\n",
    "    \"\"\"\n",
    "    global history\n",
    "    # Ejecutar la cadena inyectando el historial actual\n",
    "    answer = chain.invoke({\"input\": user_text, \"chat_history\": history})\n",
    "    # Actualizar memoria (guardar los dos mensajes)\n",
    "    history += [HumanMessage(content=user_text), AIMessage(content=answer)]\n",
    "    return answer\n",
    "\n",
    "# --- Ejemplo de uso (tres turnos) ---\n",
    "print(chat(\"Hola, soy un profesor de informática.\"))\n",
    "print(chat(\"¿Puedes explicarme cómo introducir IA a mis estudiantes?\"))\n",
    "print(chat(\"¿Qué ejemplos prácticos puedo usar en la clase?\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a79423b",
   "metadata": {},
   "source": [
    "### Explicación\n",
    "- **ConversationBufferMemory:** almacena los mensajes anteriores en la conversación.\n",
    "- **ConversationChain:** combina el modelo con la memoria.\n",
    "- Esta funcionalidad es útil para tutores inteligentes o chatbots educativos que requieren continuidad en el diálogo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba0ab9",
   "metadata": {},
   "source": [
    "## 6️⃣ Buenas prácticas con LangChain + OpenAI\n",
    "- Usa prompts **claros y estructurados**: el modelo responde mejor cuando la tarea está bien definida.\n",
    "- Controla `temperature` según la tarea: bajo (0.1–0.3) para precisión, alto (0.7–0.9) para creatividad.\n",
    "- Guarda logs o historiales si tu aplicación incluye interacción prolongada.\n",
    "- Limita la longitud de las respuestas con `max_tokens` para evitar costos o respuestas excesivas.\n",
    "- Documenta tus cadenas (`LLMChain`) para reusarlas en distintos contextos educativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a40d49",
   "metadata": {},
   "source": [
    "## ✅ Conclusión\n",
    "Has aprendido los fundamentos de LangChain: prompts, chains, memoria y flujo secuencial. Estos conceptos son la base para desarrollar asistentes educativos, tutores personalizados o sistemas de generación de contenido en el aula. En la próxima guía implementaremos un **asistente educativo con RAG (Retrieval-Augmented Generation)** usando tus propios materiales docentes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
